{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Algorithm Analysis Using Big-Oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are We Doing?\n",
    "\n",
    "* Characterizing the <font color=Red>running times</font> of algorithms using <font color=Red>Big-Oh notation</font>\n",
    "\n",
    "* Over the next few notebooks we'll be doing an example <font color=Red>for each</font> of the <font color=Red>seven fundamental functions</font> we discussed in the last notebook.\n",
    "\n",
    "* We'll be demonstrating <font color=Red>three different techniques</font> to perform Big-Oh analysis where each subsequent technique will use less explicit or formal justification, so the analysis will get faster with each subsequent technique.  \n",
    "\n",
    "* Three Techniques for Performing Big-Oh Analysis:\n",
    "\n",
    "  * Use the definition of Big-Oh on the calculated running time \n",
    "  * Use Big-Oh rules on the calculated running time\n",
    "  * Identify the line(s) responsible for the largest growth rate\n",
    "\n",
    "Note (1): Using these three different techniques allows us to see how all of the topics we have covered so far come into play as well as being able to see why we're able to ignore particular steps and details if we just want to be able to quickly come to an answer.\n",
    "\n",
    "Note (2): In these examples we'll be analyzing Python implementations of algorithms as opposed to the previously discussed pseudocode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Performing Big-Oh Analysis\n",
    "\n",
    "  1. Identify each primitive operation in the code block\n",
    "\n",
    "  2. Count how many times each primitive operation is executed\n",
    "  \n",
    "  3. Calculate the running time by summing the counts of primitive operations\n",
    "  \n",
    "  4. Perform a Big-Oh analysis on the computed running time\n",
    " \n",
    "Note (3): When counting primitive operations we'll ignore the line beginning with the keyword $def$ which serves as the functionâ€™s signature since we care about the running time of the function's body.\n",
    "\n",
    "Note (4): Remember we're assuming all primitive operations will have the same constant execution time which allows us to simply count how many times each primitive operation executes and sum up the resulting counts.\n",
    "\n",
    "Note (5): Also remember if we know a finite number of primitive operations are executing but we can't count the exact amount since the implementation details are being abstracted away (like in Python for loops), then we'll use constant variables to represent the number of executed primitive operations for that line of code.    \n",
    "\n",
    "Note (6): This approach of using constant variables will still allow us to use Big-Oh analysis to correctly identify the growth rate since Big-Oh allows us to ignore lower-order terms and constant factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Time Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 1\n",
    "\n",
    "result = a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\color{blue}{a = 0}$, is $\\color{blue}{1}$ operation since we're assigning a value of $0$ to the variable $a$.\n",
    "\n",
    "* $\\color{blue}{b = 1}$, is also $\\color{blue}{1}$ operation since we're assigning a value of $1$ to the variable $b$.\n",
    "\n",
    "* $\\color{blue}{result = a + b}$, is $\\color{blue}{2}$ operations since we're performing an arithmetic operation and assigning the computation to the variable result. \n",
    "\n",
    "Therefore, the total running time of the algorithm is:\n",
    "\n",
    "$$t = \\color{blue}{1 + 1 + 2} = 4$$.\n",
    "\n",
    "### Using the Definition of Big-Oh on the Calculated Running Time\n",
    "\n",
    "* If you remember the definition of Big-Oh is the following:\n",
    "\n",
    "  Let $f(n)$ and $g(n)$ be functions mapping positive integers to positive real numbers.\n",
    "\n",
    "  We say $f(n)$ $\\epsilon$ $O(g(n))$ if there is a real constant $c > 0$ and an integer constant $n_0 \\geq 1$ such that\n",
    "\n",
    "  $f(n) \\leq cg(n)$, for all $n \\geq n_0$.\n",
    "\n",
    "  So, we need to determine a real constant $c > 0$ and an integer constant $n_0 \\geq 1$ such that $f(n) \\leq cg(n)$ for all $n \\geq n_0$.\n",
    "\n",
    "  Here, $f(n) = t = 4$.\n",
    "\n",
    "  If we let $c = 5$, then \n",
    "\n",
    "  $4 \\leq 5g(n)$ for all $n \\geq n_0$.\n",
    "\n",
    "  If we let $g(n) = 1$, then\n",
    "\n",
    "  $4 \\leq 5(1)$ for all $n \\geq n_0$.\n",
    "\n",
    "  If we let $n_0 = 1$, then\n",
    "\n",
    "  $4 \\leq 5$ for all $n \\geq 1$.\n",
    "\n",
    "  Therefore, $t = 4$ is $O(1)$.\n",
    "  \n",
    "Note (7): Our choice for $c$ and $n_0$ are one of infinitely many choices that can demonstrate $f(n)$ is $O(g(n))$, e.g., we could have chosen $c = 10$ and $n_0 = 2$.\n",
    "\n",
    "### Using Big-Oh Rules on the Calculated Running Time\n",
    "\n",
    "* Instead of going through the long-winded process of using the definition we can use some Big-Oh rules to perform the analysis.\n",
    "\n",
    "* We'll be using the following two rules:\n",
    "\n",
    "  * **Use the smallest/closet possible class of functions**, e.g., $f(n) = 7n$ is $O(n)$ instead of $f(n) = 7n$ is $O(n^3)$.\n",
    "  * **Use the simplest expression of the class of function**, e.g., $f(n) = 6n^2 + 5n + 8$ is $O(n^2)$ instead of $f(n) = 6n^2 + 5n + 8$ is $O(6n^2)$.\n",
    "\n",
    "* Here, we have $t = 4$, so the smallest/closest possible class of function and the simplest expression of the determined class of function that can characterize the behavior of $t$ is $O(1)$.\n",
    "\n",
    "### Identifying the Line(s) Responsible for the Largest Growth Rate \n",
    "\n",
    "* Using this technique we won't even need to calculate the running time $t$.\n",
    "\n",
    "* We can just look at the code and recognize that all of the lines consist of primitive operations that are executed one time, so the running time in terms of Big-Oh is $O(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Time Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In a future notebook we'll be analyzing the <font color=Red>binary search</font> algorithm.  \n",
    "\n",
    "* We're delaying the analysis because it will be beneficial to first go over what binary search does, how it works, and the visualization of some examples.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Time Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the product of the elements in the list A of length n.\n",
    "def calculateProduct(A):\n",
    "    product = 1\n",
    "    for i in A:\n",
    "        product *= i\n",
    "    return product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\color{blue}{product = 1}$, is $\\color{blue}{1}$ operation since we're assigning a value of $1$ to the variable $product$.\n",
    "\n",
    "* $\\color{blue}{for}$ $\\color{blue}{i}$ $\\color{blue}{in}$ $\\color{blue}{A}$$\\color{blue}{:}$, is $\\color{blue}{c_1 + c_2n}$ operations where if you remember $c_1$ represents the constant number of primitive operations associated with the initializing and the terminating of the for loop, and $c_2$ represents the number of primitive operations associated with the maintenance of the iterator which is done $n$ times.\n",
    "\n",
    "* $\\color{blue}{product}$ $\\color{blue}{*= i}$, is $\\color{blue}{2n}$ operations since we're performing an arithmetic operation and assigning the result to the variable $product$ during each iteration of the loop. \n",
    "\n",
    "* $\\color{blue}{return}$ $\\color{blue}{product}$, is $\\color{blue}{1}$ operation since we're returning the variable $product$ from the function.\n",
    "\n",
    "Therefore, the total running time of the algorithm is:\n",
    "\n",
    "$$t = \\color{blue}{1 + c_1 + c_2n + 2n + 1} = 2 + c_1 + c_2n + 2n$$.\n",
    "\n",
    "### Using the Definition of Big-Oh on the Calculated Running Time\n",
    "\n",
    "* We need to determine a real constant $c > 0$ and an integer constant $n_0 \\geq 1$ such that $f(n) \\leq cg(n)$ for all $n \\geq n_0$.\n",
    "\n",
    "  Here, $f(n) = t = 2 + c_1 + c_2n + 2n$.\n",
    "\n",
    "  If we let $c = 2 + c_1 + c_2 + 2$, then \n",
    "\n",
    "  $2 + c_1 + c_2n + 2n \\leq (2 + c_1 + c_2 + 2)g(n)$ for all $n \\geq n_0$.\n",
    "\n",
    "  If we let $g(n) = n$, then\n",
    "\n",
    "  $2 + c_1 + c_2n + 2n \\leq (2 + c_1 + c_2 + 2)n$ for all $n \\geq n_0$.\n",
    "\n",
    "  If we let $n_0 = 1$, then\n",
    "\n",
    "  $2 + c_1 + c_2n + 2n \\leq (2 + c_1 + c_2 + 2)n$ for all $n \\geq 1$.\n",
    "\n",
    "  Therefore, $t = 2 + c_1 + c_2n + 2n$ is $O(n)$.\n",
    "\n",
    "### Using Big-Oh Rules on the Calculated Running Time\n",
    "\n",
    "* We'll be using the two rules we used in the previous example.\n",
    "\n",
    "* Here, we have $t = 2 + c_1 + c_2n + 2n$, so the smallest/closest possible class of function and the simplest expression of the determined class of function that can characterize the behavior of $t$ is $O(n)$.\n",
    "\n",
    "### Identifying the Line(s) Responsible for the Largest Growth Rate \n",
    "\n",
    "* Once again using this technique means we won't even need to calculate the running time $t$. We can just look at the code and recognize that the for loop consists of $n$ iterations, so it will cause the running time in terms of Big-Oh to be $O(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Log-N Time Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We'll be analyzing the <font color=Red>merge sort</font> algorithm in a future notebook for the same reasons as the logarithmic time example.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Time Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if the intersection of the three sequences of numbers, A, B, and C is empty.\n",
    "# In other words determine if there is no element x such that x belongs to A, B, and C.\n",
    "# We'll assume each list has a length of n and that no individual sequence contains \n",
    "# duplicate values, but there may be numbers that are in two or three of the sequences\n",
    "# E.g., A = [1, 2, 3], B = [1, 2, 4], C = [1, 5, 6] is fine since no individual sequence \n",
    "# has duplicate values, but A = [1, 2, 2], B = [2, 3, 4], and C = [2, 4, 5] is not fine \n",
    "# since 2 is a duplicated value in A.\n",
    "def threeWaySetDisjointness(A, B, C):\n",
    "    for a in A:\n",
    "        for b in B:\n",
    "            if a == b:\n",
    "                for c in C:\n",
    "                    if a == c:\n",
    "                        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\color{blue}{for}$ $\\color{blue}{a}$ $\\color{blue}{in}$ $\\color{blue}{A}$$\\color{blue}{:}$, is again $\\color{blue}{c_1 + c_2n}$ operations for the same reasons as the previous example.\n",
    "\n",
    "* $\\color{blue}{for}$ $\\color{blue}{b}$ $\\color{blue}{in}$ $\\color{blue}{B}$$\\color{blue}{:}$, is $\\color{blue}{c_1n + c_2n^2}$ operations since the loop is executed $n$ times which means the loop consists of $c_1 + c_2n$ operations for each iteration of the outer loop which is also executed $n$ times, so the number of operations for this line is $(c_1 + c_2n)*n = c_1n + c_2n^2$.\n",
    "\n",
    "* $\\color{blue}{if}$ $\\color{blue}{a}$ $\\color{blue}{==}$ $\\color{blue}{b}$$\\color{blue}{:}$, is $\\color{blue}{n^2}$ operations since we're comparing two numbers during each iteration of the loop over list $B$ which is executed $n$ times for each iteration of the outer loop which is also executed $n$ times, so the number of operations is $n*n=n^2$.\n",
    "\n",
    "* $\\color{blue}{for}$ $\\color{blue}{c}$ $\\color{blue}{in}$ $\\color{blue}{C}$$\\color{blue}{:}$, is $\\color{blue}{c_1n + c_2n^2}$ operations since we're assuming no individual list has duplicate values. This assumption means there will be at most $n$ pairs of $a$ and $b$ that are equal since each value in $A$ can only be equal to at most one value in $B$. This means in the worst case the loop over list $C$ consists of $c_1 + c_2n$ operations each time $a$ is equal to be $b$ which in the worst case happens $n$ times, so the number of operations for this line is $(c_1 + c_2n)n = c_1n + c_2n^2$.\n",
    "\n",
    "* $\\color{blue}{if}$ $\\color{blue}{a}$ $\\color{blue}{==}$ $\\color{blue}{c}$$\\color{blue}{:}$, is $\\color{blue}{n^2}$ operations since we're comparing two numbers during each iteration of the loop over list $C$ which is executed $n$ times for each time $a$ is equal to $b$ which in our case is $n$ times, so the number of operations is $n*n=n^2$.\n",
    "\n",
    "* $\\color{blue}{return}$ $\\color{blue}{True}$, is $\\color{blue}{1}$ operation since we're returning a value from a function. This line will be executed in the worst case because each loop will have completed execution without finding a common value between $A$, $B$, and $C$.\n",
    "\n",
    "Therefore, the total running time of the algorithm is:\n",
    "\n",
    "$$t = \\color{blue}{c_1 + c_2n + c_1n + c_2n^2 + n^2 + c_1n + c_2n^2 + n^2 + 1} = c_1 + c_2n + 2c_1n + 2c_2n^2 + 2n^2 + 1$$.\n",
    "\n",
    "Note (8): We're assuming the constant variables associated with the execution of a loop are the same.\n",
    "\n",
    "### Using the Definition of Big-Oh on the Calculated Running Time\n",
    "\n",
    "* We need to determine a real constant $c > 0$ and an integer constant $n_0 \\geq 1$ such that $f(n) \\leq cg(n)$ for all $n \\geq n_0$.\n",
    "\n",
    "  Here, $f(n) = t = c_1 + c_2n + 2c_1n + 2c_2n^2 + 2n^2 + 1$.\n",
    "\n",
    "  If we let $c = c_1 + c_2 + 2c_1 + 2c_2 + 2 + 1$, then \n",
    "\n",
    "  $c_1 + c_2n + 2c_1n + 2c_2n^2 + 2n^2 + 1 \\leq (c_1 + c_2 + 2c_1 + 2c_2 + 2 + 1)g(n)$ for all $n \\geq n_0$.\n",
    "\n",
    "  If we let $g(n) = n^2$, then\n",
    "\n",
    "  $c_1 + c_2n + 2c_1n + 2c_2n^2 + 2n^2 + 1 \\leq (c_1 + c_2 + 2c_1 + 2c_2 + 2 + 1)n^2$ for all $n \\geq n_0$.\n",
    "\n",
    "  If we let $n_0 = 1$, then\n",
    "\n",
    "  $c_1 + c_2n + 2c_1n + 2c_2n^2 + 2n^2 + 1 \\leq (c_1 + c_2 + 2c_1 + 2c_2 + 2 + 1)n^2$ for all $n \\geq 1$.\n",
    "\n",
    "  Therefore, $t = c_1 + c_2n + 2c_1n + 2c_2n^2 + 2n^2 + 1$ is $O(n^2)$.\n",
    "\n",
    "### Using Big-Oh Rules on the Calculated Running Time\n",
    "\n",
    "* We'll be using the two rules we used in the previous examples.\n",
    "\n",
    "* Here, we have $t = c_1 + c_2n + 2c_1n + 2c_2n^2 + 2n^2 + 1$, so the smallest/closest possible class of function and the simplest expression of the determined class of function that can characterize the behavior of $t$ is $O(n^2)$.\n",
    "\n",
    "### Identifying the Line(s) Responsible for the Largest Growth Rate \n",
    "\n",
    "* Once again we won't need to calculate the running time $t$ to properly analyze the algorithm in terms of Big-Oh. \n",
    "\n",
    "* We can look at the code and recognize that the nested for loop used with list $B$ consists of $n^2$ iterations.\n",
    "\n",
    "* Now, even though we have a deeper nested for loop used with list $C$ we know it will only execute when $a$ is equal to $b$ which will happen at most $n$ times.\n",
    "\n",
    "* We know $a$ is equal to $b$ at most $n$ times because like we previously said there are no duplicate values in any individual lists, e.g., $A = [1, 2, 3]$ but $A \\neq [1, 1, 2]$, so each value in $A$ can only be equal to at most one value in $B$.\n",
    "\n",
    "* Now, each time $a$ is equal to $b$ which in the worst case is $n$ times the loop used with list $C$ will execute in the worst case $n$ times. \n",
    "\n",
    "* This means the loop used with list $C$ consists of $n^2$ iterations. \n",
    "\n",
    "* So, the largest growth rate present in the algorithm is $n^2$ which means the running time in terms of Big-Oh is $O(n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
